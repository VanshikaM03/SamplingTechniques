{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYHPpFlbZQi6wVChezqTkw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanshikaM03/SamplingTechniques/blob/main/SamplingTechniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WNwLwgcq7wF",
        "outputId": "9c411753-a7f0-489e-f60b-853d20efae43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Dataset:\n",
            "    Time        V1        V2        V3        V4        V5        V6  \\\n",
            "0    265 -0.491003  0.906953  1.645423 -0.083531 -0.195560 -0.710165   \n",
            "1    184 -0.143256  0.743649  1.534072  1.062170  0.208187 -0.838623   \n",
            "2    566  1.166360  0.005061  0.497768  0.798920 -0.365524 -0.233421   \n",
            "3    128  1.239495 -0.182609  0.155058 -0.928892 -0.746227 -1.235608   \n",
            "4    246 -1.069200  1.239963  0.545157  1.005354 -0.025696 -0.910673   \n",
            "5    441 -0.565329 -0.061420  2.197934 -1.958795 -0.048529  0.748808   \n",
            "6    574 -0.402057  0.584300  2.474227  0.929684  0.014314  0.297490   \n",
            "7     85  1.327884 -0.735012  1.502449 -0.544105 -1.909350 -0.712498   \n",
            "8     44  0.927060 -0.323684  0.387585  0.544474  0.246787  1.650358   \n",
            "9      0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
            "10   118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n",
            "11   164  0.073497  0.551033  0.451890  0.114964  0.822947  0.251480   \n",
            "12   406 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
            "13   472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
            "14   484 -0.928088  0.398194  1.741131  0.182673  0.966387 -0.901004   \n",
            "15   529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
            "16   539 -1.738582  0.052740  1.187057 -0.656652  0.920623 -0.291788   \n",
            "17   574  1.257719  0.364739  0.306923  0.690638 -0.357792 -1.067481   \n",
            "\n",
            "          V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
            "0   0.559119  0.116340 -0.538190  ... -0.168067 -0.517387  0.018650  0.491652   \n",
            "1   0.524151 -0.294661 -0.478856  ... -0.205014 -0.460893  0.047407  0.339243   \n",
            "2  -0.074210 -0.008325  0.437687  ... -0.195728 -0.365798  0.030729  0.123133   \n",
            "3  -0.061695 -0.125223  0.984938  ...  0.146077  0.481119 -0.140019  0.538261   \n",
            "4   0.422442  0.049283 -0.564601  ...  0.146555  0.602990  0.132656  0.427113   \n",
            "5   0.296588 -0.149943  1.209929  ...  0.104993  0.885525 -0.548767 -0.711467   \n",
            "6   0.715195 -0.257153  0.593868  ... -0.072812  0.445733 -0.245103  0.421234   \n",
            "7  -1.292820 -0.002715 -0.246028  ...  0.461092  1.308647 -0.046031  0.764375   \n",
            "8  -0.427576  0.615371  0.226278  ... -0.040513  0.079359  0.096632 -0.992569   \n",
            "9  -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
            "10  0.086781 -0.202836  0.035154  ... -0.287592 -0.832682  0.128083  0.339427   \n",
            "11  0.296319  0.139497 -0.123050  ... -0.128758 -0.381932  0.151012 -1.363967   \n",
            "12 -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211  0.320198   \n",
            "13  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966 -0.293803   \n",
            "14  0.879016 -0.156590 -0.142117  ...  0.066353  0.281378 -0.257966  0.385384   \n",
            "15 -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836 -0.857105   \n",
            "16  0.269083  0.140631  0.023464  ... -0.179545 -0.192036 -0.261879 -0.237477   \n",
            "17  0.094272 -0.210300  0.014455  ... -0.286856 -0.820658  0.127663  0.343128   \n",
            "\n",
            "         V25       V26       V27       V28  Amount  Class  \n",
            "0  -0.277795  0.043841  0.253372  0.111749    9.03      0  \n",
            "1  -0.779439  0.234456 -0.024125 -0.049898    1.98      0  \n",
            "2   0.381749  0.296735 -0.007175  0.011905   18.56      0  \n",
            "3   0.710720 -0.621382  0.036867  0.010963    8.80      0  \n",
            "4  -0.084030 -0.417194 -0.897885 -0.462042    2.98      0  \n",
            "5   0.267147  0.242160 -0.306742 -0.410484   50.00      0  \n",
            "6   0.049280 -0.388323 -0.329333 -0.386747   12.00      0  \n",
            "7   0.281841 -0.063753  0.060406  0.037296   11.99      0  \n",
            "8   0.085096  0.377447  0.036096 -0.005960   45.71      0  \n",
            "9   0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
            "10  0.215944  0.094704 -0.023354  0.030892    2.69      1  \n",
            "11 -1.389079  0.075412  0.231750  0.230171    0.99      1  \n",
            "12  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
            "13  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
            "14  0.391117 -0.453853 -0.104448 -0.125765    1.00      1  \n",
            "15 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n",
            "16 -0.335040  0.240323 -0.345129 -0.383563    1.00      1  \n",
            "17  0.221120  0.094391 -0.022189  0.030944    1.29      1  \n",
            "\n",
            "[18 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "# pip install -U imbalanced-learn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/Creditcard_data.csv')\n",
        "\n",
        "X = df.drop(df.columns[-1], axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Apply random undersampling\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "\n",
        "# Display the balanced dataset\n",
        "balanced_df = pd.DataFrame(X_resampled)\n",
        "balanced_df['Class'] = y_resampled\n",
        "print(\"Balanced Dataset:\")\n",
        "print(balanced_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "confidence_level = 0.95\n",
        "margin_of_error = 0.05\n",
        "z_score = 1.96  # corresponds to a 95% confidence level\n",
        "\n",
        "population_std_dev = 10\n",
        "\n",
        "# Calculate sample size using the formula\n",
        "sample_size = int((z_score**2 * population_std_dev**2) / margin_of_error**2)\n",
        "\n",
        "# Generate five samples of a balanced dataset\n",
        "num_samples = 5\n",
        "datasets = []\n",
        "\n",
        "for i in range(num_samples):\n",
        "\n",
        "    class_size = int(sample_size / 2)\n",
        "    sample_class_0 = np.random.normal(loc=20, scale=population_std_dev, size=class_size)\n",
        "    sample_class_1 = np.random.normal(loc=25, scale=population_std_dev, size=class_size)\n",
        "\n",
        "    # Combine the samples into a balanced dataset\n",
        "    sample_data = np.concatenate([sample_class_0, sample_class_1])\n",
        "    labels = np.concatenate([np.zeros(class_size), np.ones(class_size)])\n",
        "\n",
        "    # Shuffle the data\n",
        "    indices = np.arange(len(sample_data))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Create a DataFrame with the specified columns\n",
        "    sample_df = pd.DataFrame({\n",
        "        'Time': np.arange(len(sample_data)),\n",
        "        'V1': sample_data[indices],\n",
        "        'V2': np.random.randn(len(sample_data)),\n",
        "        'V3': np.random.randn(len(sample_data)),\n",
        "        'V4': np.random.randn(len(sample_data)),\n",
        "        'V5': np.random.randn(len(sample_data)),\n",
        "        'V6': np.random.randn(len(sample_data)),\n",
        "        'V7': np.random.randn(len(sample_data)),\n",
        "        'V8': np.random.randn(len(sample_data)),\n",
        "        'V9': np.random.randn(len(sample_data)),\n",
        "        'V10': np.random.randn(len(sample_data)),\n",
        "        'V11': np.random.randn(len(sample_data)),\n",
        "        'V12': np.random.randn(len(sample_data)),\n",
        "        'V13': np.random.randn(len(sample_data)),\n",
        "        'V14': np.random.randn(len(sample_data)),\n",
        "        'V15': np.random.randn(len(sample_data)),\n",
        "        'V16': np.random.randn(len(sample_data)),\n",
        "        'V17': np.random.randn(len(sample_data)),\n",
        "        'V18': np.random.randn(len(sample_data)),\n",
        "        'V19': np.random.randn(len(sample_data)),\n",
        "        'V20': np.random.randn(len(sample_data)),\n",
        "        'V21': np.random.randn(len(sample_data)),\n",
        "        'V22': np.random.randn(len(sample_data)),\n",
        "        'V23': np.random.randn(len(sample_data)),\n",
        "        'V24': np.random.randn(len(sample_data)),\n",
        "        'V25': np.random.randn(len(sample_data)),\n",
        "        'V26': np.random.randn(len(sample_data)),\n",
        "        'V27': np.random.randn(len(sample_data)),\n",
        "        'V28': np.random.randn(len(sample_data)),\n",
        "        'Amount': np.random.rand(len(sample_data)),\n",
        "        'Class': labels[indices]\n",
        "    })\n",
        "\n",
        "    datasets.append(sample_df)\n",
        "\n",
        "# Display the five balanced datasets\n",
        "for i, dataset in enumerate(datasets):\n",
        "    print(f\"Sample {i+1} - Sample Size: {len(dataset)}\")\n",
        "    print(dataset.head())\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJxBNNUoyQ9v",
        "outputId": "30f56726-24e0-481a-9177-c4f19a9116d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 - Sample Size: 153662\n",
            "   Time         V1        V2        V3        V4        V5        V6  \\\n",
            "0     0  16.567589  2.641317 -0.462491 -0.243610  0.062274  0.428737   \n",
            "1     1  17.069391  0.978730  1.044005 -1.613027  1.084557  0.208681   \n",
            "2     2  10.733856  0.427459 -0.517065  0.373304 -1.656489  0.048872   \n",
            "3     3  34.652845  1.724001  0.937477 -0.234831  2.592550 -0.891846   \n",
            "4     4  32.969954  0.612516 -0.558884 -0.507351  0.608229 -1.706851   \n",
            "\n",
            "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
            "0  1.441998 -0.944268  0.212485  ... -1.212516 -0.396778  0.610096  0.940050   \n",
            "1  1.531104 -0.104994  1.191623  ... -0.785847  0.888588 -0.473404 -0.379854   \n",
            "2  0.764776  1.133396  0.334913  ... -0.559830  0.908217  0.639849  1.100489   \n",
            "3 -0.323094  0.820967  1.375619  ... -1.053024 -1.005678 -0.015265  0.519623   \n",
            "4 -1.440403 -0.347440 -0.190116  ... -3.026914 -1.091345  0.536649 -0.239563   \n",
            "\n",
            "        V25       V26       V27       V28    Amount  Class  \n",
            "0 -0.351000  1.190523  0.975561  0.163763  0.678274    0.0  \n",
            "1  0.706822  1.141081 -0.223158  0.611412  0.963901    0.0  \n",
            "2 -2.399298 -0.594915  0.578808 -0.723545  0.547423    0.0  \n",
            "3  0.415473  0.165318  1.694276 -0.237139  0.958424    0.0  \n",
            "4 -2.132928  0.012627 -2.019409 -0.154582  0.448202    0.0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "\n",
            "Sample 2 - Sample Size: 153662\n",
            "   Time         V1        V2        V3        V4        V5        V6  \\\n",
            "0     0  16.554193 -1.187343 -2.779866  0.662582  0.602561 -0.386569   \n",
            "1     1  36.248706  0.023018  0.135145  0.433905 -1.163933  1.170445   \n",
            "2     2  19.972366  0.945999 -1.635713  2.578107 -0.523680 -0.044467   \n",
            "3     3  22.918113  0.046132  0.806570 -2.141470  1.440322 -0.890146   \n",
            "4     4  25.265571 -0.532633 -0.027809  0.339391 -1.705323 -1.869488   \n",
            "\n",
            "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
            "0 -0.453007 -1.681204 -0.902093  ...  0.592960 -1.155022  1.031831  0.488296   \n",
            "1  0.137176  0.393424 -2.743077  ...  0.054305  0.176836 -0.355844  0.369266   \n",
            "2  0.203442 -0.659137  0.360782  ...  1.266173  0.694818  0.055133  2.225261   \n",
            "3 -0.032711 -0.716349  1.348293  ...  0.880250  0.235137 -0.042282  0.048223   \n",
            "4 -0.130830  0.025401  0.026827  ...  0.811304 -0.225045  0.610287 -0.494091   \n",
            "\n",
            "        V25       V26       V27       V28    Amount  Class  \n",
            "0  0.039109 -0.968335 -0.704504 -0.137621  0.280255    0.0  \n",
            "1  1.300885 -2.400407  1.087600  0.493594  0.093744    1.0  \n",
            "2 -0.174427 -0.140529 -0.111203  1.080509  0.625915    1.0  \n",
            "3 -0.429387  1.162844  1.514285  0.525824  0.179629    0.0  \n",
            "4  0.537013 -0.287450 -0.545488  0.161434  0.231362    1.0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "\n",
            "Sample 3 - Sample Size: 153662\n",
            "   Time         V1        V2        V3        V4        V5        V6  \\\n",
            "0     0   8.328442 -0.928987  0.191239  0.431768  1.253475 -0.858638   \n",
            "1     1  45.380144 -1.191486  1.006810  0.878920  0.408647 -0.492434   \n",
            "2     2   8.631297 -0.784127  0.836521  0.340505  0.825562 -0.246900   \n",
            "3     3  22.292329 -0.308596 -0.264787 -0.889764  0.873699  0.765316   \n",
            "4     4  44.224863  1.970389  0.118681 -0.996311  1.016164  0.437817   \n",
            "\n",
            "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
            "0 -1.250403 -1.347803 -1.668386  ...  0.323455 -0.444211 -0.595570  0.247505   \n",
            "1  0.314515  1.340903  0.362193  ... -0.146041 -1.037116 -0.431742  2.144905   \n",
            "2 -0.169139 -0.569860  0.697051  ... -0.207929  0.704046 -1.702251 -0.436320   \n",
            "3  0.021067  0.824831  0.121140  ... -0.385906  0.795904  0.115917 -1.820364   \n",
            "4 -1.214187  0.200302  1.856045  ... -2.071383 -0.435443  0.285163 -1.132810   \n",
            "\n",
            "        V25       V26       V27       V28    Amount  Class  \n",
            "0  0.690666  0.655607 -0.515402  0.143232  0.978609    0.0  \n",
            "1 -1.498615  0.834405 -0.214326  1.048591  0.961879    1.0  \n",
            "2 -0.380416  0.407983  0.323522  0.769473  0.743949    1.0  \n",
            "3  0.567939  0.040984 -1.686173 -1.048556  0.434177    1.0  \n",
            "4 -0.699885 -1.267159 -0.111419  1.540888  0.915442    1.0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "\n",
            "Sample 4 - Sample Size: 153662\n",
            "   Time         V1        V2        V3        V4        V5        V6  \\\n",
            "0     0  26.066740  0.392584  0.370301 -0.327291  0.392038  0.391432   \n",
            "1     1  20.900491 -0.488194 -0.013220  0.447226 -0.381854 -0.720782   \n",
            "2     2  18.955084 -0.083077  2.583722 -0.229083 -2.035961 -1.007912   \n",
            "3     3  10.505839 -1.397703 -1.396920 -0.903857 -0.462515  1.880252   \n",
            "4     4  36.573351 -1.118413  1.247072  0.351503 -0.123712  1.164380   \n",
            "\n",
            "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
            "0 -0.154068 -0.604660 -0.971035  ...  1.388907  0.013024  0.191336 -1.730379   \n",
            "1 -1.603332  0.764061 -1.624135  ...  1.214027  0.175755 -0.202225  0.055399   \n",
            "2 -0.198901  0.161651  0.158106  ...  0.001474  0.032537  1.249419 -0.358589   \n",
            "3 -0.889108  0.629556  1.398891  ...  0.453983  0.569262 -1.498285  0.330332   \n",
            "4  0.869530  0.912611 -0.482891  ... -1.858658  0.764947  0.395188  0.540550   \n",
            "\n",
            "        V25       V26       V27       V28    Amount  Class  \n",
            "0 -1.659796  0.914820 -0.092848 -1.681267  0.179920    1.0  \n",
            "1 -0.928092 -1.664723 -1.339547 -0.950561  0.182554    1.0  \n",
            "2  0.396915  1.328317 -0.769716 -0.736221  0.765585    0.0  \n",
            "3 -0.949761  0.546298 -1.969759  0.490989  0.086234    0.0  \n",
            "4  0.994819 -0.685634  1.222933 -0.424878  0.054950    1.0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "\n",
            "Sample 5 - Sample Size: 153662\n",
            "   Time         V1        V2        V3        V4        V5        V6  \\\n",
            "0     0  20.642365  1.118994  0.454404 -0.751251 -0.158363  1.357766   \n",
            "1     1  11.159433 -0.297962 -1.143712 -0.571974  0.360809 -1.043963   \n",
            "2     2  10.646235  0.540061  0.760343 -0.024159 -0.139879  0.928196   \n",
            "3     3  28.898289 -0.154639  0.607249 -0.382316  0.091335 -0.812899   \n",
            "4     4  26.002078 -0.994735  0.271220 -1.846863  0.841115  0.233862   \n",
            "\n",
            "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
            "0  0.184421 -0.381750 -0.984872  ... -0.424936  0.715913 -1.034175 -0.184417   \n",
            "1  0.658810 -0.332451  1.000656  ... -1.101932 -1.831910  0.043057  1.186464   \n",
            "2  0.785468  1.288999  1.610272  ... -0.723126 -0.598860  0.080447  0.343089   \n",
            "3 -1.173499 -0.529095  1.351261  ...  1.802979 -0.719218  0.727680  0.767182   \n",
            "4 -0.983003  0.368355 -0.013437  ... -0.118604 -0.188304 -1.615486 -1.599239   \n",
            "\n",
            "        V25       V26       V27       V28    Amount  Class  \n",
            "0  1.920700  1.016182 -0.871563 -2.032507  0.115483    1.0  \n",
            "1  1.357140  0.118350 -1.018299  0.468249  0.865582    1.0  \n",
            "2 -0.216239  0.484228  0.687184 -2.457963  0.152802    0.0  \n",
            "3  0.823398 -0.874885  1.348735 -0.220031  0.917297    1.0  \n",
            "4  0.105127  1.151347  0.252840  0.584846  0.234512    1.0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "# Features and labels\n",
        "X = balanced_df.drop('Class', axis=1)\n",
        "y = balanced_df['Class']\n",
        "\n",
        "# Define ML models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'k-NN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Sampling techniques\n",
        "sampling_techniques = {\n",
        "    'Simple Random Sampling': lambda data: data.sample(frac=1, random_state=42),\n",
        "    'Stratified Sampling': lambda data: data.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=0.8, random_state=42)),\n",
        "    'Systematic Sampling': lambda data: data.iloc[::2],\n",
        "    'Cluster Sampling': lambda data: data.groupby('Class').apply(lambda x: x.sample(frac=0.8, random_state=42)).reset_index(drop=True),\n",
        "    'Stratified Random Sampling': lambda data: data.groupby('Class', group_keys=False).apply(lambda x: x.sample(frac=0.8, random_state=42)),\n",
        "}\n",
        "\n",
        "# Train and evaluate models with different sampling techniques\n",
        "results_matrix = pd.DataFrame(index=models.keys(), columns=sampling_techniques.keys())\n",
        "\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    for technique_name, technique in sampling_techniques.items():\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Apply sampling technique on the training set\n",
        "        sampled_df = technique(pd.concat([X_train, y_train], axis=1))\n",
        "        X_train_sampled = sampled_df.drop('Class', axis=1)\n",
        "        y_train_sampled = sampled_df['Class']\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train_sampled, y_train_sampled)\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Store the results\n",
        "        results_matrix.loc[model_name, technique_name] = accuracy\n",
        "\n",
        "# Display the results\n",
        "print(results_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noBw8NLB0H0-",
        "outputId": "0e4ee4f9-5954-4fc9-fb17-34c90d054350"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Simple Random Sampling Stratified Sampling  \\\n",
            "Logistic Regression                   0.25                0.25   \n",
            "Decision Tree                         0.75                0.75   \n",
            "Random Forest                         0.25                 0.5   \n",
            "SVM                                    0.0                 0.0   \n",
            "k-NN                                  0.25                 0.0   \n",
            "\n",
            "                    Systematic Sampling Cluster Sampling  \\\n",
            "Logistic Regression                0.75             0.25   \n",
            "Decision Tree                      0.25              0.5   \n",
            "Random Forest                       0.0             0.25   \n",
            "SVM                                0.75              0.0   \n",
            "k-NN                               0.75              0.0   \n",
            "\n",
            "                    Stratified Random Sampling  \n",
            "Logistic Regression                       0.25  \n",
            "Decision Tree                             0.75  \n",
            "Random Forest                             0.25  \n",
            "SVM                                        0.0  \n",
            "k-NN                                       0.0  \n"
          ]
        }
      ]
    }
  ]
}